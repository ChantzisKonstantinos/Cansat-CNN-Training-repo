{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PSXN--IuOath",
    "outputId": "df694e0b-6f58-47ca-adcb-adab99d13a07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset EuroSAT\n",
      "    Number of datapoints: 20827\n",
      "    Root location: ./data\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               ToTensor()\n",
      "               Normalize(mean=[0.5], std=[0.5])\n",
      "           )\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean = [0.5], std = [0.5])\n",
    "])\n",
    "\n",
    "data = torchvision.datasets.EuroSAT(root = './data', download = True, transform = transform)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HOIaCyXoQAFE",
    "outputId": "9d7cad92-0db3-4ad2-aa1a-c5465d3f197d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AnnualCrop', 'Forest', 'HerbaceousVegetation', 'Highway', 'Industrial', 'Pasture', 'Residential', 'River']\n",
      "torch.Size([20827, 3, 64, 64])\n",
      "torch.Size([20827])\n"
     ]
    }
   ],
   "source": [
    "classes = data.classes\n",
    "print(classes)\n",
    "\n",
    "images = []\n",
    "labels = []\n",
    "for img, label in data:\n",
    "    images.append(img)\n",
    "    labels.append(label)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "X = torch.stack(images).to(device)\n",
    "y = torch.tensor(labels).to(device)\n",
    "\n",
    "X.\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a8IxQA6QQAPb",
    "outputId": "bef27824-0831-4520-8d88-b6a13feb481f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20827, 3, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 42)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "xDq47NM7lZQn"
   },
   "outputs": [],
   "source": [
    "batchSize = 32\n",
    "trainDataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "trainLoader = torch.utils.data.DataLoader(trainDataset, batch_size = batchSize, shuffle = True)\n",
    "\n",
    "testDataset = torch.utils.data.TensorDataset(X_test, y_test)\n",
    "testLoader = torch.utils.data.DataLoader(testDataset, batch_size = batchSize, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7NIsLWEBQARx",
    "outputId": "865d7505-1a53-4940-d38a-c0ee850901b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18744, 3, 64, 64])\n",
      "torch.Size([18744])\n",
      "torch.Size([2083, 3, 64, 64])\n",
      "torch.Size([2083])\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "byKeI5ZRQAUY",
    "outputId": "1417d4cd-b272-408a-855a-a29c9e325b66"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (fc1): Linear(in_features=8192, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
      "  (dropfc1): Dropout(p=0.2, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class CNN(nn.Module):\n",
    "  def __init__(self, inChannels, numClasses):\n",
    "    super(CNN, self).__init__()\n",
    "    self.conv1 = nn.Conv2d(in_channels = inChannels, out_channels= 16, kernel_size = 3, stride = 1, padding = 1)\n",
    "    self.pool = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "    self.conv2 = nn.Conv2d(in_channels = 16, out_channels = 32, kernel_size = 3, stride = 1, padding = 1)\n",
    "    self.fc1 = nn.Linear(32 * 16 * 16, 128)\n",
    "    self.fc2 = nn.Linear(128, numClasses)\n",
    "    self.dropfc1 = nn.Dropout(p=0.2)\n",
    "    # self.dropconv2 = nn.Dropout2d(p=0.1)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = F.relu(self.conv1(x))\n",
    "    x = self.pool(x)\n",
    "    x = F.relu(self.conv2(x))\n",
    "    x = self.pool(x)\n",
    "    x = x.view(-1, 32 * 16 * 16)\n",
    "    x = F.relu(self.dropfc1(self.fc1(x)))\n",
    "    x = self.fc2(x)\n",
    "    return x\n",
    "  def Pri(self):\n",
    "      print(\"sususu\")\n",
    "\n",
    "model = CNN(inChannels = 3, numClasses = 10).to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "oGc3No1PQAWd"
   },
   "outputs": [],
   "source": [
    "#Hyper parameters\n",
    "learningRate = 1e-3\n",
    "epochs = 70\n",
    "lossFunction = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = learningRate)\n",
    "scheduler = lr_scheduler.LinearLR(optimizer,start_factor = 1.0, end_factor= 0.1, total_iters= 50)\n",
    "losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X52988CwqcOK",
    "outputId": "5b2cec78-e40a-4197-be02-5d519537f483"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.029363819, Lr: 0.000982\n",
      "Epoch 2, Loss: 0.020720524, Lr: 0.000964\n",
      "Epoch 3, Loss: 0.031179596, Lr: 0.000946\n",
      "Epoch 4, Loss: 0.011550658, Lr: 0.000928\n",
      "Epoch 5, Loss: 0.022334508, Lr: 0.00091\n",
      "Epoch 6, Loss: 0.012342612, Lr: 0.000892\n",
      "Epoch 7, Loss: 0.019630678, Lr: 0.000874\n",
      "Epoch 8, Loss: 0.017632081, Lr: 0.000856\n",
      "Epoch 9, Loss: 0.009886972, Lr: 0.000838\n",
      "Epoch 10, Loss: 0.018860901, Lr: 0.00082\n",
      "Epoch 11, Loss: 0.016754675, Lr: 0.000802\n",
      "Epoch 12, Loss: 0.018825842, Lr: 0.000784\n",
      "Epoch 13, Loss: 0.009570366, Lr: 0.000766\n",
      "Epoch 14, Loss: 0.015139647, Lr: 0.000748\n",
      "Epoch 15, Loss: 0.014139303, Lr: 0.00073\n",
      "Epoch 16, Loss: 0.008893348, Lr: 0.000712\n",
      "Epoch 17, Loss: 0.010071772, Lr: 0.000694\n",
      "Epoch 18, Loss: 0.014410808, Lr: 0.000676\n",
      "Epoch 19, Loss: 0.012974727, Lr: 0.000658\n",
      "Epoch 20, Loss: 0.012572528, Lr: 0.00064\n",
      "Epoch 21, Loss: 0.006358754, Lr: 0.000622\n",
      "Epoch 22, Loss: 0.010961068, Lr: 0.000604\n",
      "Epoch 23, Loss: 0.012290421, Lr: 0.000586\n",
      "Epoch 24, Loss: 0.006612038, Lr: 0.000568\n",
      "Epoch 25, Loss: 0.004443303, Lr: 0.00055\n",
      "Epoch 26, Loss: 0.006834056, Lr: 0.000532\n",
      "Epoch 27, Loss: 0.004530896, Lr: 0.000514\n",
      "Epoch 28, Loss: 0.005974023, Lr: 0.000496\n",
      "Epoch 29, Loss: 0.010349246, Lr: 0.000478\n",
      "Epoch 30, Loss: 0.007767006, Lr: 0.00046\n",
      "Epoch 31, Loss: 0.005388529, Lr: 0.000442\n",
      "Epoch 32, Loss: 0.005504026, Lr: 0.000424\n",
      "Epoch 33, Loss: 0.005415468, Lr: 0.000406\n",
      "Epoch 34, Loss: 0.005430607, Lr: 0.000388\n",
      "Epoch 35, Loss: 0.003339032, Lr: 0.00037\n",
      "Epoch 36, Loss: 0.006935657, Lr: 0.000352\n",
      "Epoch 37, Loss: 0.004644141, Lr: 0.000334\n",
      "Epoch 38, Loss: 0.003640081, Lr: 0.000316\n",
      "Epoch 39, Loss: 0.003822595, Lr: 0.000298\n",
      "Epoch 40, Loss: 0.004548461, Lr: 0.00028\n",
      "Epoch 41, Loss: 0.003491983, Lr: 0.000262\n",
      "Epoch 42, Loss: 0.003604716, Lr: 0.000244\n",
      "Epoch 43, Loss: 0.003891041, Lr: 0.000226\n",
      "Epoch 44, Loss: 0.002025511, Lr: 0.000208\n",
      "Epoch 45, Loss: 0.003183166, Lr: 0.00019\n",
      "Epoch 46, Loss: 0.003541598, Lr: 0.000172\n",
      "Epoch 47, Loss: 0.001709406, Lr: 0.000154\n",
      "Epoch 48, Loss: 0.002308102, Lr: 0.000136\n",
      "Epoch 49, Loss: 0.001822371, Lr: 0.000118\n",
      "Epoch 50, Loss: 0.002767181, Lr: 0.0001\n",
      "Epoch 51, Loss: 0.002359831, Lr: 0.0001\n",
      "Epoch 52, Loss: 0.001702176, Lr: 0.0001\n",
      "Epoch 53, Loss: 0.002005212, Lr: 0.0001\n",
      "Epoch 54, Loss: 0.001475901, Lr: 0.0001\n",
      "Epoch 55, Loss: 0.000979623, Lr: 0.0001\n",
      "Epoch 56, Loss: 0.001288554, Lr: 0.0001\n",
      "Epoch 57, Loss: 0.002713087, Lr: 0.0001\n",
      "Epoch 58, Loss: 0.001789375, Lr: 0.0001\n",
      "Epoch 59, Loss: 0.002243190, Lr: 0.0001\n",
      "Epoch 60, Loss: 0.001710667, Lr: 0.0001\n",
      "Epoch 61, Loss: 0.002134797, Lr: 0.0001\n",
      "Epoch 62, Loss: 0.001802341, Lr: 0.0001\n",
      "Epoch 63, Loss: 0.000973009, Lr: 0.0001\n",
      "Epoch 64, Loss: 0.001994545, Lr: 0.0001\n",
      "Epoch 65, Loss: 0.002251836, Lr: 0.0001\n",
      "Epoch 66, Loss: 0.001947745, Lr: 0.0001\n",
      "Epoch 67, Loss: 0.001241575, Lr: 0.0001\n",
      "Epoch 68, Loss: 0.001661411, Lr: 0.0001\n",
      "Epoch 69, Loss: 0.001740616, Lr: 0.0001\n",
      "Epoch 70, Loss: 0.001955585, Lr: 0.0001\n"
     ]
    }
   ],
   "source": [
    "def train():\n",
    "  for epoch in range(epochs):\n",
    "    epochLoss = 0\n",
    "    numBatches = 0\n",
    "    for X, y in trainLoader:\n",
    "      optimizer.zero_grad()\n",
    "      pred = model(X)\n",
    "      loss = lossFunction(pred, y)\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      epochLoss += loss.item()\n",
    "      numBatches += 1\n",
    "    scheduler.step()\n",
    "    avgLoss = epochLoss/numBatches\n",
    "    losses.append(avgLoss)\n",
    "    print(f'Epoch {epoch+1}, Loss: {avgLoss:.9f}, Lr: {optimizer.param_groups[0][\"lr\"]:.6}')\n",
    "\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H0Xfy4gVramL",
    "outputId": "8ce51a1a-f19c-487b-9946-fa6ab51b1d46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 1831/2083 with accuracy 87.90%\n"
     ]
    }
   ],
   "source": [
    "def check_accuracy():\n",
    "\n",
    "\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient calculation\n",
    "        for x, y in testLoader:\n",
    "\n",
    "            # Forward pass: compute the model output\n",
    "            scores = model(x)\n",
    "            _, predictions = scores.max(1)  # Get the index of the max log-probability\n",
    "            num_correct += (predictions == y).sum()  # Count correct predictions\n",
    "            num_samples += predictions.size(0)  # Count total samples\n",
    "\n",
    "        # Calculate accuracy\n",
    "        accuracy = float(num_correct) / float(num_samples) * 100 \n",
    "        print(f\"Got {num_correct}/{num_samples} with accuracy {accuracy:.2f}%\")\n",
    "\n",
    "    model.train()  # Set the model back to training mode\n",
    "\n",
    "# Final accuracy check on training and test sets\n",
    "check_accuracy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m5vyqKimaVF8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
